{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "willing-sustainability",
   "metadata": {},
   "source": [
    "## Multioutput model\n",
    "\n",
    "Now, we need a model to detect the type of hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dense-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "\n",
    "with open(\"../data/train.json\") as f:\n",
    "    train_articles = json.load(f)\n",
    "\n",
    "with open(\"../data/test.json\") as f:\n",
    "    test_articles = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excellent-fence",
   "metadata": {},
   "source": [
    "Let's take just the comments that are HATEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "comic-dryer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5140 hateful comments in train\n",
      "We have 1285 hateful comments in dev\n",
      "We have 1676 hateful comments in test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "train_comments = [c for article in train_articles for c in article[\"comments\"] if c[\"is_hateful\"]]\n",
    "test_comments = [c for article in test_articles for c in article[\"comments\"] if c[\"is_hateful\"]]\n",
    "\n",
    "train_df = pd.DataFrame(train_comments)\n",
    "test_df = pd.DataFrame(test_comments)\n",
    "\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "print(f\"We have {len(train_df)} hateful comments in train\")\n",
    "print(f\"We have {len(dev_df)} hateful comments in dev\")\n",
    "print(f\"We have {len(test_df)} hateful comments in test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "angry-istanbul",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls         0.041419\n",
       "WOMEN        -0.045314\n",
       "LGBTI        -0.019344\n",
       "RACISM        0.036614\n",
       "CLASS        -0.020343\n",
       "POLITICS     -0.027052\n",
       "DISABLED     -0.012728\n",
       "APPEARANCE   -0.012631\n",
       "CRIMINAL      0.077931\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = [\n",
    "    \"calls\",\n",
    "    \"WOMEN\",\n",
    "    \"LGBTI\",\n",
    "    \"RACISM\",\n",
    "    \"CLASS\",\n",
    "    \"POLITICS\",\n",
    "    \"DISABLED\",\n",
    "    \"APPEARANCE\",\n",
    "    \"CRIMINAL\",\n",
    "]\n",
    "\n",
    "train_df[categories].mean() - test_df[categories].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-karen",
   "metadata": {},
   "source": [
    "It is slightly unbalanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "another-certificate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "user_regex = re.compile(r\"@[a-zA-Z0-9_]{0,15}\")\n",
    "url_regex = re.compile(\n",
    "    \"((?<=[^a-zA-Z0-9])(?:https?\\:\\/\\/|[a-zA-Z0-9]{1,}\\.{1}|\\b)(?:\\w{1,}\\.{1}){1,5}(?:com|co|org|edu|gov|uk|net|ca|de|jp|fr|au|us|ru|ch|it|nl|se|no|es|mil|iq|io|ac|ly|sm){1}(?:\\/[a-zA-Z0-9]{1,})*)\"\n",
    ")\n",
    "\n",
    "def preprocess_tweet(text):\n",
    "    \"\"\"\n",
    "    Basic preprocessing\n",
    "    \"\"\"\n",
    "    text = user_regex.sub(\"usuario\", text)\n",
    "    text = url_regex.sub(\"url\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "global-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_tweet)\n",
    "dev_df[\"text\"] = dev_df[\"text\"].apply(preprocess_tweet)\n",
    "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "photographic-seller",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8366)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Supongamos que tenemos un batch de 32 \n",
    "Por cada uno\n",
    "\"\"\"\n",
    "\n",
    "logits = torch.randn(32, 8)\n",
    "labels = torch.Tensor([[1, 1, 1, 1, 0, 0, 0, 0] for _ in range(32)])\n",
    "\n",
    "\n",
    "loss_fct = BCEWithLogitsLoss()\n",
    "loss_fct(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "detected-theory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1403e-05)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[-10, -9, -10]])\n",
    "target = torch.zeros(1, 3)\n",
    "\n",
    "loss_fct(\n",
    "    logits,\n",
    "    target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-richardson",
   "metadata": {},
   "source": [
    "¿Está haciendo lo esperado esto? Veamos...\n",
    "\n",
    "Cross entropy es \n",
    "\n",
    "$- [y \\log \\hat{y} + (1-y) \\log (1-\\hat{y}) ]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sticky-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.1410e-05)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "pred = sigmoid(logits)\n",
    "\n",
    "losses = -(target * torch.log(pred) + (1 - target) * torch.log(1-pred))\n",
    "\n",
    "losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-queen",
   "metadata": {},
   "source": [
    "Espectacular!!! \n",
    "\n",
    "Qué pasa con el weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "painted-group",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.3217e-05), tensor(7.1526e-05))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "pred = sigmoid(logits)\n",
    "\n",
    "weights = torch.Tensor([0.5, 0.1, 0.4])\n",
    "\n",
    "losses = -(target * torch.log(pred) + (1 - target) * torch.log(1-pred))\n",
    "\n",
    "loss_fct = BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "(losses * weights).sum(), loss_fct(logits, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-mayor",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hummm...no me queda claro **CHEQUEAR ESTO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "waiting-transmission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import BertPreTrainedModel, BertTokenizer, BertModel\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "\n",
    "class BertForSequenceMultiClassification(BertPreTrainedModel):\n",
    "    \"\"\"\n",
    "    Slight modification of BertForSequenceClassification to allow for multipĺe classification\n",
    "    heads\n",
    "    \n",
    "    In fact, the only modification is the change of the loss! We use a BCEWith\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        The same as BertForSequenceClassification\n",
    "        \"\"\"\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "    ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size,)`, `optional`):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in :obj:`[0, ...,\n",
    "            config.num_labels - 1]`. If :obj:`config.num_labels == 1` a regression loss is computed (Mean-Square loss),\n",
    "            If :obj:`config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            \"\"\"\n",
    "            The only thing I change is here!\n",
    "            \"\"\"\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "documented-width",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceMultiClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceMultiClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "id2label = {0: 'Not hateful', 1: 'Hateful'}\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "model = BertForSequenceMultiClassification.from_pretrained(model_name, return_dict=True, num_labels=len(categories))\n",
    "\n",
    "model.config.hidden_dropout_prob = 0.20\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "model = model.to(device)\n",
    "model.train();\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unauthorized-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "\n",
    "#examples = pd.concat([train_df, dev_df])\n",
    "\n",
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "})\n",
    "\n",
    "for cat in categories:\n",
    "    features[cat] = ClassLabel(num_classes=2, names=[\"NO\", \"YES\"])\n",
    "\n",
    "columns = [\"text\"] + categories\n",
    "train_dataset = Dataset.from_pandas(train_df[columns], features=features)\n",
    "dev_dataset = Dataset.from_pandas(dev_df[columns], features=features)\n",
    "test_dataset = Dataset.from_pandas(test_df[columns], features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "taken-worthy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36dd330739444580822be3fa5ce77a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090075bc5b3c4ee3bcd561a4a2bfff17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8d31cd791e4c37bc0b9414ba9d4139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reflected-clark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf63e88edae4b56a91c0b036fb39553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5140.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff6a2cb1721415d909692be4c98049d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc482d657354c62a70ee3593f0aaaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1676.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    def sarasa(examples):\n",
    "        return {'labels': torch.Tensor([examples[cat] for cat in categories])}\n",
    "    dataset = dataset.map(sarasa)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-colorado",
   "metadata": {},
   "source": [
    "Esta API de mierda vive cambiando todo el tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "absent-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for Trainer\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    \n",
    "    labels = pred.label_ids\n",
    "    preds = torch.sigmoid(torch.Tensor(pred.predictions)).round()\n",
    "\n",
    "    ret = {\n",
    "    }\n",
    "    \"\"\"\n",
    "    Calculo F1 por cada posición. Asumo que cada categoría está alineada correctamente en la i-ésima posición\n",
    "    \"\"\"\n",
    "    f1s = []\n",
    "    for i, cat in enumerate(categories):\n",
    "        cat_labels, cat_preds = labels[:, i], preds[:, i]\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(cat_labels, cat_preds, average='macro')\n",
    "        \n",
    "        f1s.append(f1)\n",
    "        \n",
    "        ret[cat+\" F1\"] = f1\n",
    "        \n",
    "    ret[\"Mean F1\"] = torch.Tensor(f1s).mean()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "consecutive-october",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='483' max='483' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [483/483 04:07, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Calls f1</th>\n",
       "      <th>Women f1</th>\n",
       "      <th>Lgbti f1</th>\n",
       "      <th>Racism f1</th>\n",
       "      <th>Class f1</th>\n",
       "      <th>Politics f1</th>\n",
       "      <th>Disabled f1</th>\n",
       "      <th>Appearance f1</th>\n",
       "      <th>Criminal f1</th>\n",
       "      <th>Mean f1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266307</td>\n",
       "      <td>0.809562</td>\n",
       "      <td>0.720145</td>\n",
       "      <td>0.491102</td>\n",
       "      <td>0.880212</td>\n",
       "      <td>0.477004</td>\n",
       "      <td>0.681807</td>\n",
       "      <td>0.481855</td>\n",
       "      <td>0.824595</td>\n",
       "      <td>0.820352</td>\n",
       "      <td>0.687404</td>\n",
       "      <td>5.328400</td>\n",
       "      <td>241.161000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208873</td>\n",
       "      <td>0.876902</td>\n",
       "      <td>0.751318</td>\n",
       "      <td>0.764767</td>\n",
       "      <td>0.910400</td>\n",
       "      <td>0.660053</td>\n",
       "      <td>0.824378</td>\n",
       "      <td>0.787424</td>\n",
       "      <td>0.883161</td>\n",
       "      <td>0.855090</td>\n",
       "      <td>0.812610</td>\n",
       "      <td>5.301300</td>\n",
       "      <td>242.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.196946</td>\n",
       "      <td>0.876672</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>0.782118</td>\n",
       "      <td>0.911128</td>\n",
       "      <td>0.745986</td>\n",
       "      <td>0.846919</td>\n",
       "      <td>0.811141</td>\n",
       "      <td>0.888411</td>\n",
       "      <td>0.865458</td>\n",
       "      <td>0.835293</td>\n",
       "      <td>5.265300</td>\n",
       "      <td>244.049000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=483, training_loss=0.24680429462567127, metrics={'train_runtime': 247.5683, 'train_samples_per_second': 1.951, 'total_flos': 1300997599810560.0, 'epoch': 3.0, 'init_mem_cpu_alloc_delta': 54763, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18258, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 785827, 'train_mem_gpu_alloc_delta': 1381010944, 'train_mem_cpu_peaked_delta': 631922, 'train_mem_gpu_peaked_delta': 3558643712})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "epochs = 3\n",
    "\n",
    "total_steps = (epochs * len(train_dataset)) // batch_size\n",
    "warmup_steps = total_steps // 10\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "taken-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, context=None):\n",
    "    sentence = preprocess_tweet(sentence)\n",
    "    idx = torch.LongTensor(tokenizer.encode(sentence)).view(1, -1).to(device)\n",
    "    output = model(idx)\n",
    "\n",
    "    output = output.logits.detach().cpu().numpy()[0]\n",
    "\n",
    "    ret = [cat for cat, out in list(zip(categories, output > 0)) if out]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "federal-trauma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negro chorro de mierda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "tribal-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Quiere bijaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "mediterranean-arnold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Le falta verga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "generous-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Trolazo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "suspended-shower",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Te llamás Raúl querido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "confident-pierce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI', 'APPEARANCE']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No seas trolo viejo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "complete-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"A esta trola hay que agarrarla de a varios para que sepa lo que es bueno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distributed-carroll",
   "metadata": {},
   "source": [
    "Acá no encuentra el llamado a la acción...ahora, si lo cambiamos ligeramente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "environmental-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calls', 'RACISM']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"A esta negra de mierda hay que agarrarla de a varios para que sepa lo que es bueno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "generic-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calls']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hay que encerrar a todos estos homosexuales de mierda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "liberal-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Qué asco de homosexuales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "approved-night",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calls', 'CRIMINAL']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Qué asco de homosexuales, mátenlos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-elements",
   "metadata": {},
   "source": [
    "Parece que correlaciona todo llamado a la acción a los criminales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "separated-vanilla",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['calls', 'RACISM']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negros chorros de mierda, cuarenta ladrillos y arreglamos esto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bearing-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"negras al paredón!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "angry-collectible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS', 'POLITICS']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No queremos rojitos acá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "secure-jumping",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No les gusta laburar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "nuclear-beaver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Agarrá la pala!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "healthy-acrobat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Agarrá la pala, vago!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "modern-portable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Menos ganas de laborar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "specific-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Viven del Estado, esta gente sinceramente no tiene remedio\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
