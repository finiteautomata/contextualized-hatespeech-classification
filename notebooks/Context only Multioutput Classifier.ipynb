{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "novel-cooling",
   "metadata": {},
   "source": [
    "## Context-only category classifier\n",
    "\n",
    "En esta notebook veamos de hacer un clasificador que sólo use el contexto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "touched-bernard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets... "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232fb405ed914d60ac32ece09083afee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62cb9aa3bf874b019704f6d20d22849f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dbed1538fc4ad2996d6c07f081ac98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Script to train hatespeech classifier\n",
    "\"\"\"\n",
    "import fire\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (\n",
    "    Trainer, TrainingArguments, AutoModelForSequenceClassification, AutoTokenizer\n",
    ")\n",
    "from hatedetection import BertForSequenceMultiClassification, load_datasets, extended_hate_categories\n",
    "from hatedetection.metrics import compute_category_metrics\n",
    "\n",
    "\n",
    "def load_model_and_tokenizer(model_name, max_length):\n",
    "    \"\"\"\n",
    "    Load model and tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    model = BertForSequenceMultiClassification.from_pretrained(\n",
    "        model_name, return_dict=True, num_labels=len(extended_hate_categories)\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.model_max_length = max_length\n",
    "\n",
    "    return model, tokenizer\n",
    "\n",
    "def tokenize(tokenizer, batch, padding='max_length', truncation=True):\n",
    "    \"\"\"\n",
    "    Apply tokenization\n",
    "\n",
    "    Arguments:\n",
    "    ---------\n",
    "\n",
    "    use_context: boolean (default True)\n",
    "        Whether to add the context to the\n",
    "    \"\"\"\n",
    "\n",
    "    return tokenizer(batch['context'], padding='max_length', truncation=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Loading datasets... \", end=\"\")\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets()\n",
    "\n",
    "train_dataset = train_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n",
    "dev_dataset = dev_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n",
    "test_dataset = test_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-ranch",
   "metadata": {},
   "source": [
    "Acá cambiamos el train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "found-photograph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['context', 'CALLS', 'WOMEN', 'LGBTI', 'RACISM', 'CLASS', 'POLITICS', 'DISABLED', 'APPEARANCE', 'CRIMINAL'],\n",
       "    num_rows: 938\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "\n",
    "\n",
    "df = pd.DataFrame(columns=[\"context\"] + extended_hate_categories)\n",
    "df.set_index(\"context\", inplace=True)\n",
    "\n",
    "for example in train_dataset:\n",
    "    for cat in extended_hate_categories:\n",
    "        if example[cat] > 0:\n",
    "            df.loc[example[\"context\"], cat] = 1\n",
    "    \n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "features = Features({\n",
    "    'context': Value('string'),\n",
    "})\n",
    "\n",
    "\n",
    "for cat in extended_hate_categories:\n",
    "    \"\"\"\n",
    "    Set for WOMEN, LGBTI...and also for CALLS\n",
    "    \"\"\"\n",
    "    features[cat] = ClassLabel(num_classes=2, names=[\"NO\", \"YES\"])\n",
    "    \n",
    "train_dataset = Dataset.from_pandas(df, features=features)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "joint-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "\n",
      "Loading model and tokenizer... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceMultiClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceMultiClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")\n",
    "max_length = 128\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Loading model and tokenizer... \", end=\"\")\n",
    "model, tokenizer = load_model_and_tokenizer(model_name, max_length)\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chicken-borough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bc64dcf16af40c19a52d9740d43a9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3c7895a3cf498c9489fb48f29a82d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159e2e8445a94aabace03430c1c65745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=113.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b376601ff4e431f97a432d3f00bbae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=938.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4a689015de4a1aa5fa367c00f9fb53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f0b9d7fe1f742e899ff265aeda7caa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1797.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "my_tokenize = lambda batch: tokenize(tokenizer, batch)\n",
    "\n",
    "train_dataset = train_dataset.map(my_tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(my_tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(my_tokenize, batched=True, batch_size=eval_batch_size)\n",
    "\n",
    "\n",
    "def format_dataset(dataset):\n",
    "    def get_category_labels(examples):\n",
    "        return {'labels': torch.Tensor([examples[cat] for cat in extended_hate_categories])}\n",
    "    dataset = dataset.map(get_category_labels)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rational-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " Training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 03:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Calls F1</th>\n",
       "      <th>Women F1</th>\n",
       "      <th>Lgbti F1</th>\n",
       "      <th>Racism F1</th>\n",
       "      <th>Class F1</th>\n",
       "      <th>Politics F1</th>\n",
       "      <th>Disabled F1</th>\n",
       "      <th>Appearance F1</th>\n",
       "      <th>Criminal F1</th>\n",
       "      <th>Mean F1</th>\n",
       "      <th>Mean Precision</th>\n",
       "      <th>Mean Recall</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.454820</td>\n",
       "      <td>0.576618</td>\n",
       "      <td>0.457567</td>\n",
       "      <td>0.475019</td>\n",
       "      <td>0.728045</td>\n",
       "      <td>0.475019</td>\n",
       "      <td>0.350546</td>\n",
       "      <td>0.546817</td>\n",
       "      <td>0.635844</td>\n",
       "      <td>0.450475</td>\n",
       "      <td>0.521772</td>\n",
       "      <td>0.554399</td>\n",
       "      <td>0.568378</td>\n",
       "      <td>5.975300</td>\n",
       "      <td>232.121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.390810</td>\n",
       "      <td>0.709518</td>\n",
       "      <td>0.771063</td>\n",
       "      <td>0.475019</td>\n",
       "      <td>0.794578</td>\n",
       "      <td>0.617639</td>\n",
       "      <td>0.572413</td>\n",
       "      <td>0.580333</td>\n",
       "      <td>0.663977</td>\n",
       "      <td>0.922859</td>\n",
       "      <td>0.678600</td>\n",
       "      <td>0.698546</td>\n",
       "      <td>0.719235</td>\n",
       "      <td>6.066300</td>\n",
       "      <td>228.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.368213</td>\n",
       "      <td>0.703577</td>\n",
       "      <td>0.777788</td>\n",
       "      <td>0.698703</td>\n",
       "      <td>0.830264</td>\n",
       "      <td>0.784830</td>\n",
       "      <td>0.627151</td>\n",
       "      <td>0.630644</td>\n",
       "      <td>0.715689</td>\n",
       "      <td>0.922682</td>\n",
       "      <td>0.743481</td>\n",
       "      <td>0.751727</td>\n",
       "      <td>0.784538</td>\n",
       "      <td>5.961700</td>\n",
       "      <td>232.653000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361994</td>\n",
       "      <td>0.691619</td>\n",
       "      <td>0.795058</td>\n",
       "      <td>0.722104</td>\n",
       "      <td>0.777589</td>\n",
       "      <td>0.765629</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.603272</td>\n",
       "      <td>0.723078</td>\n",
       "      <td>0.924132</td>\n",
       "      <td>0.734381</td>\n",
       "      <td>0.743162</td>\n",
       "      <td>0.774535</td>\n",
       "      <td>5.931700</td>\n",
       "      <td>233.829000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.370474</td>\n",
       "      <td>0.695512</td>\n",
       "      <td>0.781806</td>\n",
       "      <td>0.802510</td>\n",
       "      <td>0.802866</td>\n",
       "      <td>0.730062</td>\n",
       "      <td>0.604266</td>\n",
       "      <td>0.625106</td>\n",
       "      <td>0.729309</td>\n",
       "      <td>0.930079</td>\n",
       "      <td>0.744613</td>\n",
       "      <td>0.737320</td>\n",
       "      <td>0.794893</td>\n",
       "      <td>5.938800</td>\n",
       "      <td>233.547000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='174' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3704743567172922,\n",
       " 'eval_calls_f1': 0.6955116397903768,\n",
       " 'eval_women_f1': 0.7818064754688584,\n",
       " 'eval_lgbti_f1': 0.8025095232151991,\n",
       " 'eval_racism_f1': 0.8028663563117158,\n",
       " 'eval_class_f1': 0.73006166390101,\n",
       " 'eval_politics_f1': 0.6042661347740503,\n",
       " 'eval_disabled_f1': 0.6251062735378481,\n",
       " 'eval_appearance_f1': 0.7293086035593406,\n",
       " 'eval_criminal_f1': 0.9300793573356751,\n",
       " 'eval_mean_f1': 0.7446129322052002,\n",
       " 'eval_mean_precision': 0.7373201847076416,\n",
       " 'eval_mean_recall': 0.7948930263519287,\n",
       " 'eval_runtime': 5.7201,\n",
       " 'eval_samples_per_second': 242.478,\n",
       " 'epoch': 5.0,\n",
       " 'eval_mem_cpu_alloc_delta': 204441,\n",
       " 'eval_mem_gpu_alloc_delta': 0,\n",
       " 'eval_mem_cpu_peaked_delta': 271473,\n",
       " 'eval_mem_gpu_peaked_delta': 69427200}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Finally, train!\n",
    "\"\"\"\n",
    "\n",
    "epochs = 5\n",
    "warmup_proportion = 0.1\n",
    "\n",
    "print(\"\\n\"*3, \"Training...\")\n",
    "\n",
    "total_steps = (epochs * len(train_dataset)) // batch_size\n",
    "warmup_steps = int(warmup_proportion * total_steps)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"mean_f1\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_category_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "brilliant-compensation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.37047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_calls_f1</th>\n",
       "      <td>0.69551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_women_f1</th>\n",
       "      <td>0.78181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_lgbti_f1</th>\n",
       "      <td>0.80251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_racism_f1</th>\n",
       "      <td>0.80287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_class_f1</th>\n",
       "      <td>0.73006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_politics_f1</th>\n",
       "      <td>0.60427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_disabled_f1</th>\n",
       "      <td>0.62511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_appearance_f1</th>\n",
       "      <td>0.72931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_criminal_f1</th>\n",
       "      <td>0.93008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_f1</th>\n",
       "      <td>0.74461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_precision</th>\n",
       "      <td>0.73732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_recall</th>\n",
       "      <td>0.79489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>6.05110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>229.21300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <td>5.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_cpu_alloc_delta</th>\n",
       "      <td>206391.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_gpu_alloc_delta</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_cpu_peaked_delta</th>\n",
       "      <td>270426.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_gpu_peaked_delta</th>\n",
       "      <td>69427200.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       0\n",
       "eval_loss                        0.37047\n",
       "eval_calls_f1                    0.69551\n",
       "eval_women_f1                    0.78181\n",
       "eval_lgbti_f1                    0.80251\n",
       "eval_racism_f1                   0.80287\n",
       "eval_class_f1                    0.73006\n",
       "eval_politics_f1                 0.60427\n",
       "eval_disabled_f1                 0.62511\n",
       "eval_appearance_f1               0.72931\n",
       "eval_criminal_f1                 0.93008\n",
       "eval_mean_f1                     0.74461\n",
       "eval_mean_precision              0.73732\n",
       "eval_mean_recall                 0.79489\n",
       "eval_runtime                     6.05110\n",
       "eval_samples_per_second        229.21300\n",
       "epoch                            5.00000\n",
       "eval_mem_cpu_alloc_delta    206391.00000\n",
       "eval_mem_gpu_alloc_delta         0.00000\n",
       "eval_mem_cpu_peaked_delta   270426.00000\n",
       "eval_mem_gpu_peaked_delta 69427200.00000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 40\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "df_results = pd.DataFrame([trainer.evaluate(dev_dataset)])\n",
    "\n",
    "df_results.T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
