{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "boring-bridge",
   "metadata": {},
   "source": [
    "## Multioutput model (without context)\n",
    "\n",
    "Now, we need a model to detect the type of hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tribal-manitoba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from hatedetection import load_datasets\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-prediction",
   "metadata": {},
   "source": [
    "Let's take just the comments that are HATEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "enclosed-invasion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c973285d944d4554919afb79a641784e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=37.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c00ba59bb44434d97c2159b5119a6b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a0e281118b448aa6e6d8c427c83ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "train_dataset = train_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n",
    "dev_dataset = dev_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n",
    "test_dataset = test_dataset.filter(lambda x: x[\"HATEFUL\"] > 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressed-nightlife",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy Loss\n",
    "\n",
    "Si tenemos nuestras categorías en $C$, queremos hacer un \"multi-tasking\" usando una loss que sea \n",
    "\n",
    "$$\n",
    "J(y, \\hat{y}) = \\frac{1}{|C|}\\sum\\limits_{c \\in C} J_c(y, \\hat{y})\n",
    "$$\n",
    "\n",
    "O sea, para cada instancia, la función de pérdida va a ser el promedio de las pérdidas para `MUJER`, `RACISMO`, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "billion-champion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7561)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from torch.nn.functional import binary_cross_entropy_with_logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Supongamos que tenemos un batch de 32 \n",
    "Por cada uno\n",
    "\"\"\"\n",
    "\n",
    "logits = torch.randn(32, 8)\n",
    "labels = torch.Tensor([[1, 1, 1, 1, 0, 0, 0, 0] for _ in range(32)])\n",
    "\n",
    "\n",
    "loss_fct = BCEWithLogitsLoss()\n",
    "loss_fct(logits, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "through-plain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.1403e-05)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.Tensor([[-10, -9, -10]])\n",
    "target = torch.zeros(1, 3)\n",
    "\n",
    "loss_fct(\n",
    "    logits,\n",
    "    target,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-carol",
   "metadata": {},
   "source": [
    "¿Está haciendo lo esperado esto? Veamos...\n",
    "\n",
    "Cross entropy es \n",
    "\n",
    "$- [y \\log \\hat{y} + (1-y) \\log (1-\\hat{y}) ]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dried-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.local/share/virtualenvs/hatespeech-classification-n4GdOxTz/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(7.1410e-05)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "pred = sigmoid(logits)\n",
    "\n",
    "losses = -(target * torch.log(pred) + (1 - target) * torch.log(1-pred))\n",
    "\n",
    "losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agricultural-development",
   "metadata": {},
   "source": [
    "Espectacular!!! \n",
    "\n",
    "Qué pasa con el weight?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "promising-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(5.3217e-05), tensor(7.1526e-05))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "pred = sigmoid(logits)\n",
    "\n",
    "weights = torch.Tensor([0.5, 0.1, 0.4])\n",
    "\n",
    "losses = -(target * torch.log(pred) + (1 - target) * torch.log(1-pred))\n",
    "\n",
    "loss_fct = BCEWithLogitsLoss(pos_weight=weights)\n",
    "\n",
    "(losses * weights).sum(), loss_fct(logits, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-complement",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hummm...no me queda claro **CHEQUEAR ESTO**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-cannon",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "Usamos nuestro modelo `hatedetection.BertForSequenceMultiClassification`. Es una leve modificación del clasificador de `transformers`\n",
    "\n",
    "Ya lo entrenamos, así que sólo lo cargamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dated-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from hatedetection import BertForSequenceMultiClassification, extended_hate_categories\n",
    "\n",
    "model_name = \"../models/bert-non-contextualized-hate-category-es/\"\n",
    "\n",
    "model = BertForSequenceMultiClassification.from_pretrained(\n",
    "    model_name,\n",
    "    return_dict=True, num_labels=len(extended_hate_categories)\n",
    ")\n",
    "\n",
    "model.eval();\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "#\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-bible",
   "metadata": {},
   "source": [
    "Armo el trainer igual sólo para evaluar, je\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charitable-hunter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a0988053ed94ea2b3d44d62b7cd3f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=173.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b02f1d687d74fd58e817712e927ab42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=87.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93768f89703a4de6b28d5ce068280af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=113.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch, context=True, padding='max_length', truncation=True):\n",
    "    \"\"\"\n",
    "    Apply tokenization\n",
    "    \n",
    "    Arguments:\n",
    "    ---------\n",
    "    \n",
    "    use_context: boolean (default True)\n",
    "        Whether to add the context to the \n",
    "    \"\"\"\n",
    "    \n",
    "    if context:\n",
    "        args = [batch['context'], batch['text']]\n",
    "    else:\n",
    "        args = [batch['text']]\n",
    "        \n",
    "    return tokenizer(*args, padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "my_tokenize = lambda x: tokenize(x, context=False)\n",
    "\n",
    "train_dataset = train_dataset.map(my_tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(my_tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(my_tokenize, batched=True, batch_size=eval_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "passing-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aba3612d0fa496fa9870ada604e887a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5531.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0781bad9e077412899313c14ff99d9c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1387.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf81b10be07c475391ebdacdcddd1bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1797.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_dataset(dataset):\n",
    "    def get_category_labels(examples):\n",
    "        return {'labels': torch.Tensor([examples[cat] for cat in extended_hate_categories])}\n",
    "    dataset = dataset.map(get_category_labels)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "boring-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hatedetection.metrics import compute_category_metrics\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_category_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-illinois",
   "metadata": {},
   "source": [
    "Hack para que se vea lindo nomás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "color-piece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='87' max='87' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87/87 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eval_loss</th>\n",
       "      <td>0.19010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_calls_f1</th>\n",
       "      <td>0.85949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_women_f1</th>\n",
       "      <td>0.82915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_lgbti_f1</th>\n",
       "      <td>0.81845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_racism_f1</th>\n",
       "      <td>0.90558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_class_f1</th>\n",
       "      <td>0.78252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_politics_f1</th>\n",
       "      <td>0.83530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_disabled_f1</th>\n",
       "      <td>0.87544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_appearance_f1</th>\n",
       "      <td>0.90792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_criminal_f1</th>\n",
       "      <td>0.87422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_f1</th>\n",
       "      <td>0.85423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_precision</th>\n",
       "      <td>0.87268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mean_recall</th>\n",
       "      <td>0.83881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_runtime</th>\n",
       "      <td>5.79000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <td>239.55100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_mem_cpu_alloc_delta</th>\n",
       "      <td>58036.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_mem_gpu_alloc_delta</th>\n",
       "      <td>439960064.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_mem_cpu_peaked_delta</th>\n",
       "      <td>18258.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>init_mem_gpu_peaked_delta</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_cpu_alloc_delta</th>\n",
       "      <td>404038.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_gpu_alloc_delta</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_cpu_peaked_delta</th>\n",
       "      <td>260744.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_mem_gpu_peaked_delta</th>\n",
       "      <td>69427200.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0\n",
       "eval_loss                         0.19010\n",
       "eval_calls_f1                     0.85949\n",
       "eval_women_f1                     0.82915\n",
       "eval_lgbti_f1                     0.81845\n",
       "eval_racism_f1                    0.90558\n",
       "eval_class_f1                     0.78252\n",
       "eval_politics_f1                  0.83530\n",
       "eval_disabled_f1                  0.87544\n",
       "eval_appearance_f1                0.90792\n",
       "eval_criminal_f1                  0.87422\n",
       "eval_mean_f1                      0.85423\n",
       "eval_mean_precision               0.87268\n",
       "eval_mean_recall                  0.83881\n",
       "eval_runtime                      5.79000\n",
       "eval_samples_per_second         239.55100\n",
       "init_mem_cpu_alloc_delta      58036.00000\n",
       "init_mem_gpu_alloc_delta  439960064.00000\n",
       "init_mem_cpu_peaked_delta     18258.00000\n",
       "init_mem_gpu_peaked_delta         0.00000\n",
       "eval_mem_cpu_alloc_delta     404038.00000\n",
       "eval_mem_gpu_alloc_delta          0.00000\n",
       "eval_mem_cpu_peaked_delta    260744.00000\n",
       "eval_mem_gpu_peaked_delta  69427200.00000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 40\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "df_results = pd.DataFrame([trainer.evaluate(dev_dataset)])\n",
    "\n",
    "df_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reverse-opposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from hatedetection.predict import predict_category\n",
    "\n",
    "def predict(sentence, context=None):\n",
    "    return predict_category(model, tokenizer, sentence, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "monetary-gabriel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negro chorro de mierda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fluid-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Quiere bija\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "organized-yacht",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Es una tortillera\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "loved-sudan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Le falta verga\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "underlying-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CALLS', 'CRIMINAL']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Metanles bala!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "destroyed-orleans",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CALLS', 'RACISM']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Volvete a Israel!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alert-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Volvete a Arabia, musulmán!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "large-protest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CALLS', 'RACISM']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Habría que limitar el acceso inmediatamente de todo oriental\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "final-morning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Te llamás Raúl querido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "smaller-beast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No seas trolo viejo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "composite-gates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"A esta TAPU hay que agarrarla de a varios para que sepa lo que es bueno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-quilt",
   "metadata": {},
   "source": [
    "Acá no encuentra el llamado a la acción...ahora, si lo cambiamos ligeramente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"A esta negra de mierda hay que agarrarla de a varios para que sepa lo que es bueno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Hay que encerrar a todos estos homosexuales de mierda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Qué asco de putos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-belgium",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Hay que matar a todos los gorilas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-consultation",
   "metadata": {},
   "source": [
    "Parece que correlaciona todo llamado a la acción a los criminales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"orientales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Estos come murciélagos te apagan la heladera a la tarde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Negros chorros de mierda, cuarenta ladrillos y arreglamos esto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"negras al paredón!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"No queremos rojitos acá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"No les gusta laburar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Agarrá la pala!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-marriage",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Agarrá la pala, vago!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-rings",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Menos ganas de laborar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-armstrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Viven del Estado, esta gente sinceramente no tiene remedio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Tenés dos pelotas entre las piernas amigazo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"jajajajaj pero ni por puta casualidad laburar, no?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-cocktail",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"más topu imposible\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"hay que mandarlos a un campo de concentración a estos musulmanes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-somewhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Fuera rusos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"Todos los indios son una caca que sólo merece morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los judíos merecen morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los chorros merecen morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los piqueteros merecen morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los palestinos merecen morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-jurisdiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los homosexuales merecen morir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los homosexuales tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los presos tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los criminales tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los españoles tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los chinos tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los italianos tienen que ser aislados de la sociedad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(\"los italianos deben ser fusilados\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
