{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stainless-botswana",
   "metadata": {},
   "source": [
    "## Multioutput model\n",
    "\n",
    "Now, we need a model to detect the type of hate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acute-dietary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "\n",
    "with open(\"../data/train.json\") as f:\n",
    "    train_articles = json.load(f)\n",
    "\n",
    "with open(\"../data/test.json\") as f:\n",
    "    test_articles = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-assurance",
   "metadata": {},
   "source": [
    "Let's take just the comments that are HATEFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beneficial-fireplace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 5140 hateful comments in train\n",
      "We have 1285 hateful comments in dev\n",
      "We have 1676 hateful comments in test\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "import pandas as pd\n",
    "\n",
    "def serialize(article, comment):\n",
    "    ret = comment.copy()\n",
    "    ret[\"context\"] = article[\"title\"]\n",
    "    return ret\n",
    "    \n",
    "\n",
    "train_comments = [serialize(article, comment) for article in train_articles for comment in article[\"comments\"] if comment[\"is_hateful\"]]\n",
    "test_comments = [serialize(article, comment) for article in test_articles for comment in article[\"comments\"] if comment[\"is_hateful\"]]\n",
    "\n",
    "\n",
    "train_df = pd.DataFrame(train_comments)\n",
    "test_df = pd.DataFrame(test_comments)\n",
    "\n",
    "train_df, dev_df = train_test_split(train_df, test_size=0.2, random_state=20212021)\n",
    "\n",
    "print(f\"We have {len(train_df)} hateful comments in train\")\n",
    "print(f\"We have {len(dev_df)} hateful comments in dev\")\n",
    "print(f\"We have {len(test_df)} hateful comments in test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "considered-handle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calls         0.041225\n",
       "WOMEN        -0.044536\n",
       "LGBTI        -0.022262\n",
       "RACISM        0.038171\n",
       "CLASS        -0.018981\n",
       "POLITICS     -0.024523\n",
       "DISABLED     -0.011560\n",
       "APPEARANCE   -0.010102\n",
       "CRIMINAL      0.077152\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_df[categories].mean() - test_df[categories].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-teach",
   "metadata": {},
   "source": [
    "It is slightly unbalanced!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "visible-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hatedetection.preprocessing import preprocess_tweet\n",
    "\n",
    "for df in [train_df, dev_df, test_df]:\n",
    "    df[\"text\"] = df[\"text\"].apply(preprocess_tweet)\n",
    "    df[\"context\"] = df[\"context\"].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protective-doctrine",
   "metadata": {},
   "source": [
    "## Clasificación\n",
    "\n",
    "Usamos nuestro modelo `hatedetection.BertForSequenceMultiClassification`. Es una leve modificación del clasificador de `transformers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-paintball",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceMultiClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceMultiClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceMultiClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from hatedetection import BertForSequenceMultiClassification\n",
    "\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-cased'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "id2label = {0: 'Not hateful', 1: 'Hateful'}\n",
    "label2id = {v:k for k,v in id2label.items()}\n",
    "\n",
    "model = BertForSequenceMultiClassification.from_pretrained(model_name, return_dict=True, num_labels=len(categories))\n",
    "\n",
    "model.config.id2label = id2label\n",
    "model.config.label2id = label2id\n",
    "\n",
    "model = model.to(device)\n",
    "model.train();\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "superior-ridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, Value, ClassLabel, Features\n",
    "\n",
    "#examples = pd.concat([train_df, dev_df])\n",
    "\n",
    "features = Features({\n",
    "    'text': Value('string'),\n",
    "    'context': Value('string'),\n",
    "})\n",
    "\n",
    "for cat in categories:\n",
    "    features[cat] = ClassLabel(num_classes=2, names=[\"NO\", \"YES\"])\n",
    "\n",
    "columns = [\"context\", \"text\"] + categories\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df[columns], features=features)\n",
    "dev_dataset = Dataset.from_pandas(dev_df[columns], features=features)\n",
    "test_dataset = Dataset.from_pandas(test_df[columns], features=features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blocked-findings",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555134e8c2114fcf9372d7db42feb87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=161.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c5fc46cf2464af0b084856739e23558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=81.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7de2e14d50406d9133b2d1e9a8d7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=105.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['context'], batch['text'], padding='max_length', truncation=True)\n",
    "\n",
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize, batched=True, batch_size=batch_size)\n",
    "dev_dataset = dev_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "test_dataset = test_dataset.map(tokenize, batched=True, batch_size=eval_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "purple-bunny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3bb0e11bd72437db3be7f0004cb37cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5140.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f65972bae647949ab4ac6cba3d7517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1285.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185e2e2e32114575af551b32a1850aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1676.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_dataset(dataset):\n",
    "    def sarasa(examples):\n",
    "        return {'labels': torch.Tensor([examples[cat] for cat in categories])}\n",
    "    dataset = dataset.map(sarasa)\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "dev_dataset = format_dataset(dev_dataset)\n",
    "test_dataset = format_dataset(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-glance",
   "metadata": {},
   "source": [
    "Esta API de mierda vive cambiando todo el tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "african-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    \"\"\"\n",
    "    Compute metrics for Trainer\n",
    "    \"\"\"    \n",
    "    labels = pred.label_ids\n",
    "    preds = torch.sigmoid(torch.Tensor(pred.predictions)).round()\n",
    "\n",
    "    ret = {\n",
    "    }\n",
    "    \"\"\"\n",
    "    Calculo F1 por cada posición. Asumo que cada categoría está alineada correctamente en la i-ésima posición\n",
    "    \"\"\"\n",
    "    f1s = []\n",
    "    for i, cat in enumerate(categories):\n",
    "        cat_labels, cat_preds = labels[:, i], preds[:, i]\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(cat_labels, cat_preds, average='macro')\n",
    "        \n",
    "        f1s.append(f1)\n",
    "        \n",
    "        ret[cat+\" F1\"] = f1\n",
    "        \n",
    "    ret[\"Mean F1\"] = torch.Tensor(f1s).mean()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "weighted-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='805' max='805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [805/805 12:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Calls f1</th>\n",
       "      <th>Women f1</th>\n",
       "      <th>Lgbti f1</th>\n",
       "      <th>Racism f1</th>\n",
       "      <th>Class f1</th>\n",
       "      <th>Politics f1</th>\n",
       "      <th>Disabled f1</th>\n",
       "      <th>Appearance f1</th>\n",
       "      <th>Criminal f1</th>\n",
       "      <th>Mean f1</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.181724</td>\n",
       "      <td>0.864354</td>\n",
       "      <td>0.801104</td>\n",
       "      <td>0.906677</td>\n",
       "      <td>0.949633</td>\n",
       "      <td>0.762255</td>\n",
       "      <td>0.832120</td>\n",
       "      <td>0.663099</td>\n",
       "      <td>0.866771</td>\n",
       "      <td>0.960744</td>\n",
       "      <td>0.845195</td>\n",
       "      <td>10.892400</td>\n",
       "      <td>117.972000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131913</td>\n",
       "      <td>0.864543</td>\n",
       "      <td>0.875970</td>\n",
       "      <td>0.931996</td>\n",
       "      <td>0.952856</td>\n",
       "      <td>0.841412</td>\n",
       "      <td>0.872669</td>\n",
       "      <td>0.839191</td>\n",
       "      <td>0.928037</td>\n",
       "      <td>0.972235</td>\n",
       "      <td>0.897657</td>\n",
       "      <td>10.765900</td>\n",
       "      <td>119.359000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120396</td>\n",
       "      <td>0.878464</td>\n",
       "      <td>0.894050</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>0.956837</td>\n",
       "      <td>0.875821</td>\n",
       "      <td>0.875178</td>\n",
       "      <td>0.886712</td>\n",
       "      <td>0.931112</td>\n",
       "      <td>0.975076</td>\n",
       "      <td>0.911953</td>\n",
       "      <td>10.838100</td>\n",
       "      <td>118.563000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.113226</td>\n",
       "      <td>0.886335</td>\n",
       "      <td>0.908481</td>\n",
       "      <td>0.934324</td>\n",
       "      <td>0.961118</td>\n",
       "      <td>0.876004</td>\n",
       "      <td>0.893410</td>\n",
       "      <td>0.892455</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.976230</td>\n",
       "      <td>0.918172</td>\n",
       "      <td>10.875800</td>\n",
       "      <td>118.152000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.113917</td>\n",
       "      <td>0.890694</td>\n",
       "      <td>0.900315</td>\n",
       "      <td>0.932587</td>\n",
       "      <td>0.961289</td>\n",
       "      <td>0.892798</td>\n",
       "      <td>0.897183</td>\n",
       "      <td>0.877159</td>\n",
       "      <td>0.937336</td>\n",
       "      <td>0.971790</td>\n",
       "      <td>0.917906</td>\n",
       "      <td>10.825900</td>\n",
       "      <td>118.697000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=805, training_loss=0.138434038102997, metrics={'train_runtime': 721.588, 'train_samples_per_second': 1.116, 'total_flos': 4336658666035200.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 54563, 'init_mem_gpu_alloc_delta': 0, 'init_mem_cpu_peaked_delta': 18258, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 611560, 'train_mem_gpu_alloc_delta': 1327355392, 'train_mem_cpu_peaked_delta': 191435828, 'train_mem_gpu_peaked_delta': 9070782464})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "epochs = 5\n",
    "\n",
    "total_steps = (epochs * len(train_dataset)) // batch_size\n",
    "warmup_steps = total_steps // 10\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    "    warmup_steps=warmup_steps,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_eval=False,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "behind-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, context=None):\n",
    "    context = preprocess_tweet(context)\n",
    "    sentence = preprocess_tweet(sentence)\n",
    "    idx = torch.LongTensor(tokenizer.encode(context, sentence)).view(1, -1).to(device)\n",
    "    output = model(idx)\n",
    "\n",
    "    output = output.logits.detach().cpu().numpy()[0]\n",
    "\n",
    "    ret = [cat for cat, out in list(zip(categories, output > 0)) if out]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "unauthorized-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM', 'CRIMINAL']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negro chorro de mierda\", context=\"Motín de presos en Devoto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "chinese-chuck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Quiere bijaaa\", context=\"Florencia Peña dio una entrevista a Infobae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "mexican-brass",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Le falta verga\", context=\"Cristiano Ronaldo metió su gol número 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "circular-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Putaldo\", context=\"Cristiano Ronaldo metió su gol número 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "former-electric",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negro sucio\", context=\"Cristiano Ronaldo metió su gol número 1000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "stretch-monitoring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Romina tiene cuerpo de camionero\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "applicable-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN', 'LGBTI']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Sos macho Romina\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "medical-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN', 'LGBTI']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Callate varón\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cosmetic-addition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Romina viene con sorpresa entre las dos gambas\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "sealed-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Viene con paquete entre las dos gambas\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "unsigned-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"es el defensor de Cambáceres\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-analysis",
   "metadata": {},
   "source": [
    "Falla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "improving-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"A esta trola hay que agarrarla de a varios para que sepa lo que es bueno\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-joyce",
   "metadata": {},
   "source": [
    "Acá no encuentra el llamado a la acción...ahora, si lo cambiamos ligeramente..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dried-ordering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WOMEN', 'RACISM']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"A esta negra trola hay que agarrarla de a varios para que sepa lo que es bueno\", context=\"Romina C nos cuenta sus vacaciones en Cancún\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "electric-comment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI', 'CRIMINAL']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Hay que encerrar a todos estos homosexuales de mierda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "attempted-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Qué asco de homosexuales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "pharmaceutical-catalog",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Qué asco de homosexuales, mátenlos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-patio",
   "metadata": {},
   "source": [
    "Parece que correlaciona todo llamado a la acción a los criminales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "upset-commander",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Negros chorros de mierda, cuarenta ladrillos y arreglamos esto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "competitive-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"negras al paredón!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "median-induction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RACISM', 'POLITICS']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No queremos rojitos acá\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "vocal-moment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"No les gusta laburar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "lesser-assurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Agarrá la pala!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "rising-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS', 'CRIMINAL']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Agarrá la pala, vago!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "figured-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Menos ganas de laborar eh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "burning-allergy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CLASS']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Viven del Estado, esta gente sinceramente no tiene remedio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "severe-county",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LGBTI']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"Tenés dos pelotas entre las piernas amigazo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "numerical-shaft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [UNK] [SEP]'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(\"🤢\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
