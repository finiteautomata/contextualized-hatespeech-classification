{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedicated-pleasure",
   "metadata": {},
   "source": [
    "## Contextualized model\n",
    "\n",
    "Let's check where the context really helps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "neural-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "declared-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from hatedetection import load_datasets\n",
    "\n",
    "train_dataset, dev_dataset, test_dataset = load_datasets(add_body=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "based-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "context_model_name = \"../models/bert-contextualized-hate-speech-es/\"\n",
    "no_context_model_name = \"../models/bert-non-contextualized-hate-speech-es\"\n",
    "full_context_model_name = \"../models/bert-title-body-hate-speech-es/\"\n",
    "\n",
    "\n",
    "context_model = AutoModelForSequenceClassification.from_pretrained(context_model_name, return_dict=True, num_labels=2)\n",
    "no_context_model = AutoModelForSequenceClassification.from_pretrained(no_context_model_name, return_dict=True, num_labels=2)\n",
    "full_context_model = AutoModelForSequenceClassification.from_pretrained(no_context_model_name, return_dict=True, num_labels=2)\n",
    "\n",
    "context_model.eval()\n",
    "no_context_model.eval()\n",
    "full_context_model.eval()\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "context_model = context_model.to(device)\n",
    "no_context_model = no_context_model.to(device)\n",
    "full_context_model = full_context_model.to(device)\n",
    "# Tienen mismo tokenizer as√≠ que todo bien\n",
    "\n",
    "no_context_tokenizer = AutoTokenizer.from_pretrained(no_context_model_name)\n",
    "context_tokenizer = AutoTokenizer.from_pretrained(context_model_name)\n",
    "full_context_tokenizer = AutoTokenizer.from_pretrained(full_context_model_name)\n",
    "\n",
    "no_context_tokenizer.model_max_length = 128\n",
    "context_tokenizer.model_max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "treated-arbor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8065314cc2c4497c81275cd175462e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231e714a26ed43ccbeb2ea262a052783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04a18a7bbb14e58a07fc708531c99f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from hatedetection.training import tokenize\n",
    "\n",
    "batch_size = 32\n",
    "eval_batch_size = 16\n",
    "\n",
    "dataset = test_dataset\n",
    "\n",
    "\n",
    "no_context_dataset = dataset.map(lambda x: tokenize(no_context_tokenizer, x, context='none'), batched=True, batch_size=eval_batch_size)\n",
    "context_dataset = dataset.map(lambda x: tokenize(context_tokenizer, x, context='title'), batched=True, batch_size=eval_batch_size)\n",
    "full_context_dataset = dataset.map(lambda x: tokenize(full_context_tokenizer, x, context='title+body'), batched=True, batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "brutal-galaxy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec2bec14b5141558338f6cfc572ad87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11343.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e10d8abbf674b818a88e11019aaa772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11343.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a268f0b30d39489886a5560e59560170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11343.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_dataset(dataset):\n",
    "    dataset = dataset.map(lambda examples: {'labels': examples['HATEFUL']})\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n",
    "    return dataset\n",
    "\n",
    "no_context_dataset = format_dataset(no_context_dataset)\n",
    "context_dataset = format_dataset(context_dataset)\n",
    "full_context_dataset = format_dataset(full_context_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-heaven",
   "metadata": {},
   "source": [
    "Lo cargamos s√≥lo para evaluar ü§ó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "unsigned-outdoors",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hatedetection.metrics import compute_hate_metrics\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=eval_batch_size,\n",
    ")\n",
    "\n",
    "\n",
    "context_trainer = Trainer(\n",
    "    model=context_model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_hate_metrics,\n",
    ")\n",
    "\n",
    "full_context_trainer = Trainer(\n",
    "    model=full_context_model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_hate_metrics,\n",
    ")\n",
    "\n",
    "no_context_trainer = Trainer(\n",
    "    model=no_context_model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_hate_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-guyana",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "persistent-retrieval",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='709' max='709' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [709/709 04:45]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='709' max='709' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [709/709 01:44]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='709' max='709' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [709/709 01:11]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 40\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "\n",
    "df_full_context_results = pd.DataFrame([full_context_trainer.evaluate(full_context_dataset)])\n",
    "df_context_results = pd.DataFrame([context_trainer.evaluate(context_dataset)])\n",
    "df_no_context_results = pd.DataFrame([no_context_trainer.evaluate(no_context_dataset)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "suffering-aircraft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_macro_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>init_mem_cpu_alloc_delta</th>\n",
       "      <th>init_mem_gpu_alloc_delta</th>\n",
       "      <th>init_mem_cpu_peaked_delta</th>\n",
       "      <th>init_mem_gpu_peaked_delta</th>\n",
       "      <th>eval_mem_cpu_alloc_delta</th>\n",
       "      <th>eval_mem_gpu_alloc_delta</th>\n",
       "      <th>eval_mem_cpu_peaked_delta</th>\n",
       "      <th>eval_mem_gpu_peaked_delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No context</th>\n",
       "      <td>0.65833</td>\n",
       "      <td>0.88945</td>\n",
       "      <td>0.63525</td>\n",
       "      <td>0.78505</td>\n",
       "      <td>0.66545</td>\n",
       "      <td>0.60768</td>\n",
       "      <td>71.59330</td>\n",
       "      <td>158.43700</td>\n",
       "      <td>43460</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>233460</td>\n",
       "      <td>0</td>\n",
       "      <td>897173</td>\n",
       "      <td>69492736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.80262</td>\n",
       "      <td>0.90505</td>\n",
       "      <td>0.66563</td>\n",
       "      <td>0.80515</td>\n",
       "      <td>0.75281</td>\n",
       "      <td>0.59655</td>\n",
       "      <td>105.10900</td>\n",
       "      <td>107.91600</td>\n",
       "      <td>52521</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>247803</td>\n",
       "      <td>0</td>\n",
       "      <td>897045</td>\n",
       "      <td>189087744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title and Body</th>\n",
       "      <td>0.81926</td>\n",
       "      <td>0.87137</td>\n",
       "      <td>0.35585</td>\n",
       "      <td>0.64220</td>\n",
       "      <td>0.86111</td>\n",
       "      <td>0.22426</td>\n",
       "      <td>286.39620</td>\n",
       "      <td>39.60600</td>\n",
       "      <td>43213</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>501766</td>\n",
       "      <td>0</td>\n",
       "      <td>887205</td>\n",
       "      <td>579272704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                eval_loss  eval_accuracy  eval_f1  eval_macro_f1  \\\n",
       "index                                                              \n",
       "No context        0.65833        0.88945  0.63525        0.78505   \n",
       "Title             0.80262        0.90505  0.66563        0.80515   \n",
       "Title and Body    0.81926        0.87137  0.35585        0.64220   \n",
       "\n",
       "                eval_precision  eval_recall  eval_runtime  \\\n",
       "index                                                       \n",
       "No context             0.66545      0.60768      71.59330   \n",
       "Title                  0.75281      0.59655     105.10900   \n",
       "Title and Body         0.86111      0.22426     286.39620   \n",
       "\n",
       "                eval_samples_per_second  init_mem_cpu_alloc_delta  \\\n",
       "index                                                               \n",
       "No context                    158.43700                     43460   \n",
       "Title                         107.91600                     52521   \n",
       "Title and Body                 39.60600                     43213   \n",
       "\n",
       "                init_mem_gpu_alloc_delta  init_mem_cpu_peaked_delta  \\\n",
       "index                                                                 \n",
       "No context                             0                      18258   \n",
       "Title                                  0                      18258   \n",
       "Title and Body                         0                      18258   \n",
       "\n",
       "                init_mem_gpu_peaked_delta  eval_mem_cpu_alloc_delta  \\\n",
       "index                                                                 \n",
       "No context                              0                    233460   \n",
       "Title                                   0                    247803   \n",
       "Title and Body                          0                    501766   \n",
       "\n",
       "                eval_mem_gpu_alloc_delta  eval_mem_cpu_peaked_delta  \\\n",
       "index                                                                 \n",
       "No context                             0                     897173   \n",
       "Title                                  0                     897045   \n",
       "Title and Body                         0                     887205   \n",
       "\n",
       "                eval_mem_gpu_peaked_delta  \n",
       "index                                      \n",
       "No context                       69492736  \n",
       "Title                           189087744  \n",
       "Title and Body                  579272704  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.concat([df_no_context_results, df_context_results, df_full_context_results])\n",
    "df_results[\"index\"] = [\"No context\", \"Title\", \"Title and Body\"]\n",
    "df_results.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-headset",
   "metadata": {},
   "source": [
    "## Dev Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "extensive-modem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_accuracy</th>\n",
       "      <th>eval_f1</th>\n",
       "      <th>eval_macro_f1</th>\n",
       "      <th>eval_precision</th>\n",
       "      <th>eval_recall</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>init_mem_cpu_alloc_delta</th>\n",
       "      <th>init_mem_gpu_alloc_delta</th>\n",
       "      <th>init_mem_cpu_peaked_delta</th>\n",
       "      <th>init_mem_gpu_peaked_delta</th>\n",
       "      <th>eval_mem_cpu_alloc_delta</th>\n",
       "      <th>eval_mem_gpu_alloc_delta</th>\n",
       "      <th>eval_mem_cpu_peaked_delta</th>\n",
       "      <th>eval_mem_gpu_peaked_delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No context</th>\n",
       "      <td>0.50128</td>\n",
       "      <td>0.90753</td>\n",
       "      <td>0.66980</td>\n",
       "      <td>0.80802</td>\n",
       "      <td>0.73431</td>\n",
       "      <td>0.61572</td>\n",
       "      <td>38.45080</td>\n",
       "      <td>236.82200</td>\n",
       "      <td>43460</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>200737</td>\n",
       "      <td>0</td>\n",
       "      <td>755193</td>\n",
       "      <td>69447680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title</th>\n",
       "      <td>0.60040</td>\n",
       "      <td>0.92554</td>\n",
       "      <td>0.73883</td>\n",
       "      <td>0.84771</td>\n",
       "      <td>0.79322</td>\n",
       "      <td>0.69142</td>\n",
       "      <td>76.05850</td>\n",
       "      <td>119.72400</td>\n",
       "      <td>52465</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>209357</td>\n",
       "      <td>0</td>\n",
       "      <td>756777</td>\n",
       "      <td>189042688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title and Body</th>\n",
       "      <td>0.85207</td>\n",
       "      <td>0.86130</td>\n",
       "      <td>0.18778</td>\n",
       "      <td>0.55598</td>\n",
       "      <td>0.86905</td>\n",
       "      <td>0.10526</td>\n",
       "      <td>156.20100</td>\n",
       "      <td>58.29700</td>\n",
       "      <td>43325</td>\n",
       "      <td>0</td>\n",
       "      <td>18258</td>\n",
       "      <td>0</td>\n",
       "      <td>430762</td>\n",
       "      <td>0</td>\n",
       "      <td>742281</td>\n",
       "      <td>579227648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                eval_loss  eval_accuracy  eval_f1  eval_macro_f1  \\\n",
       "index                                                              \n",
       "No context        0.50128        0.90753  0.66980        0.80802   \n",
       "Title             0.60040        0.92554  0.73883        0.84771   \n",
       "Title and Body    0.85207        0.86130  0.18778        0.55598   \n",
       "\n",
       "                eval_precision  eval_recall  eval_runtime  \\\n",
       "index                                                       \n",
       "No context             0.73431      0.61572      38.45080   \n",
       "Title                  0.79322      0.69142      76.05850   \n",
       "Title and Body         0.86905      0.10526     156.20100   \n",
       "\n",
       "                eval_samples_per_second  init_mem_cpu_alloc_delta  \\\n",
       "index                                                               \n",
       "No context                    236.82200                     43460   \n",
       "Title                         119.72400                     52465   \n",
       "Title and Body                 58.29700                     43325   \n",
       "\n",
       "                init_mem_gpu_alloc_delta  init_mem_cpu_peaked_delta  \\\n",
       "index                                                                 \n",
       "No context                             0                      18258   \n",
       "Title                                  0                      18258   \n",
       "Title and Body                         0                      18258   \n",
       "\n",
       "                init_mem_gpu_peaked_delta  eval_mem_cpu_alloc_delta  \\\n",
       "index                                                                 \n",
       "No context                              0                    200737   \n",
       "Title                                   0                    209357   \n",
       "Title and Body                          0                    430762   \n",
       "\n",
       "                eval_mem_gpu_alloc_delta  eval_mem_cpu_peaked_delta  \\\n",
       "index                                                                 \n",
       "No context                             0                     755193   \n",
       "Title                                  0                     756777   \n",
       "Title and Body                         0                     742281   \n",
       "\n",
       "                eval_mem_gpu_peaked_delta  \n",
       "index                                      \n",
       "No context                       69447680  \n",
       "Title                           189042688  \n",
       "Title and Body                  579227648  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results = pd.concat([df_no_context_results, df_context_results, df_full_context_results])\n",
    "df_results[\"index\"] = [\"No context\", \"Title\", \"Title and Body\"]\n",
    "df_results.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "greenhouse-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] [USER] ojal√° se funda y cague de hambre [SEP] mora godoy cierra su escuela de tango y remata su vestuario para \" poder seguir adelante \" [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = context_dataset[0]\n",
    "\n",
    "context_tokenizer.decode(example[\"input_ids\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
